:PROPERTIES:
:ID:       d3d6a55a-a534-4d1d-b2f9-a77ef6b25e5f
:END:
#+title: Machine Learning
* 概要
機械学習は、データから学習によって自動で改善するコンピュータアルゴリズムのこと。
* Memo
* Tasks
** TODO [[https://yutaroogawa.github.io/pytorch_tutorials_jp/][PyTorchチュートリアル（日本語翻訳版）]]
Google Colaboratoryを使ったチュートリアル。
* Reference
** [[https://aizine.ai/tensor-0917/][機械学習で使う数学を学ぶなら覚えておこう！「テンソル」とは | AIZINE（エーアイジン）]]
テンソルの解説。
** [[https://ja.wikipedia.org/wiki/TensorFlow][TensorFlow - Wikipedia]]
テンソルを扱うためのライブラリ。機械学習に用いる。テンソルは多次元データの集合体のこと。
** [[https://ja.wikipedia.org/wiki/BERT_(%E8%A8%80%E8%AA%9E%E3%83%A2%E3%83%87%E3%83%AB)][BERT (言語モデル) - Wikipedia]]
自然言語処理の事前学習用のTransformerベースの機械学習手法。
** [[https://ja.wikipedia.org/wiki/Transformer_(%E6%A9%9F%E6%A2%B0%E5%AD%A6%E7%BF%92%E3%83%A2%E3%83%87%E3%83%AB)][Transformer (機械学習モデル) - Wikipedia]]
主に自然言語処理の分野で使用される深層学習モデル。
** [[https://ja.wikipedia.org/wiki/CUDA][CUDA - Wikipedia]]
NVIDIAが開発しているプラットフォームおよびプログラミングモデル。
* Archives
** DONE [[https://www.youtube.com/watch?v=xzzTYL90M8s][高校数学からはじめる深層学習入門(畳み込みニューラルネットワークの理解) - YouTube]]
CLOSED: [2024-06-30 Sun 22:07]
:LOGBOOK:
CLOCK: [2024-06-30 Sun 21:42]--[2024-06-30 Sun 22:07] =>  0:25
CLOCK: [2024-06-30 Sun 21:14]--[2024-06-30 Sun 21:39] =>  0:25
CLOCK: [2024-06-30 Sun 20:34]--[2024-06-30 Sun 20:59] =>  0:25
CLOCK: [2024-06-30 Sun 20:09]--[2024-06-30 Sun 20:34] =>  0:25
:END:
深層学習の解説。

- 学習 :: 重みを最適化していくこと(=誤差関数を最小化)
- 隠れ層が2つ以上あるものが深層学習という
- 1次関数は合成しても1次関数
- 活性化関数。値がある一定以下だと無視して、一定以上だと次に伝えてほしいような性質が必要
- プーリング層。位置がある程度変化しても、値が変わりにくいメリットがある(頑健性を獲得)
- ソフトマックス関数。分母は大きい値のときにその値が大きくなるように強調する。分子は合計を1にする(規格化)
  - 0~1の値をとり、総和が1。確率に対応している。出力層でほしいのは確率の形式なので
- 誤差関数。交差エントロピーで計算する。間違っているときは大きく、正しいときは小さくなる
  - 教師データが(1, 0, 0)で、予測が(0.8, 0.1, 0.1)のとき、0.09。小さい値
  - 教師データが(1, 0, 0)で、予測が(0.2, 0.7, 0.1)のとき、1.61。大きい値
